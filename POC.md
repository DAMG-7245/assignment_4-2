## Proof of Concept (PoC)

The Proof of Concept demonstrates the end-to-end functionality of the RAG pipeline through the following workflow:

### Step-by-Step Workflow:

#### **User Interaction via Streamlit:**
1. **User uploads NVIDIA quarterly financial report PDFs.**
2. **Selects PDF parser method:**
   - Basic Parser (PyMuPDF-based)
   - Docling Parser
   - Mistral OCR (for scanned or complex PDFs)
3. **Chooses RAG retrieval method:**
   - Naive manual embeddings with cosine similarity
   - Pinecone vector database
   - ChromaDB vector database
4. **Selects chunking strategy:**
   - Fixed-size chunking
   - Semantic chunking
   - Sliding-window chunking
5. **Filters data by specific quarter(s) or year(s).**
6. **Submits a natural language query** related to NVIDIA's financial performance or strategic insights.

---

#### **Backend Processing via FastAPI:**
1. Receives user selections and query parameters from the Streamlit frontend.
2. Triggers Airflow DAGs if new PDFs are uploaded:
   - Downloads and stores raw PDFs in storage.
   - Parses PDFs using selected parser(s).
   - Extracted text is stored in structured storage (processed quarterly).
3. Applies selected chunking strategy to processed data.
4. Generates embeddings using the selected RAG method.
5. Performs hybrid search combining semantic similarity and metadata filtering based on the user's quarter/year selection.

---

#### **LLM Integration:**
1. Hybrid search retrieves relevant document chunks as context.
2. Contextual chunks are passed to Mistral AI LLM.
3. LLM generates a concise, accurate response to the user's query.

---

#### **Returning Results:**
1. FastAPI backend returns the generated response to the Streamlit frontend.
2. User views the contextually accurate answer alongside relevant document references.

---

### Demonstration Scenario Example:

1. User uploads NVIDIA Q1 2024 financial report PDF.
2. Selects "Mistral OCR" parser due to scanned document complexity.
3. Chooses "ChromaDB" for advanced semantic retrieval.
4. Selects "Semantic Chunking" strategy for optimized context retrieval.
5. Filters data specifically for Q1 2024.
6. Queries: *"What were NVIDIA's key revenue drivers in Q1 2024?"*

**System Response:**

The system accurately extracts relevant sections from the PDF using Mistral OCR, generates embeddings stored in ChromaDB, retrieves semantically relevant chunks filtered by quarter metadata, and provides a clear response generated by Mistral AI LLM:

> *"In Q1 2024, NVIDIA's key revenue drivers included robust growth in AI-driven data center solutions, increased adoption of generative AI technologies across enterprise clients, and strong performance in gaming GPU sales."*

---

